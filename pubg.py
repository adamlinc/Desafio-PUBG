# -*- coding: utf-8 -*-
"""PUBG.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pbhvEiaUC7eVeGI-tRpFyTn7o5FJqpMU

# ***Introdução ao desafio***
Kaggle - Desafio Battleground

![alt text](https://i1.wp.com/gamepress.com.br/wp-content/uploads/2018/03/pubg.jpg?fit=768%2C465&ssl=1)


PlayerUnknown's Battlegrounds é um jogo de ação da Pubg Corp. onde 100 players simultâneos são lançados de um avião em um mapa de 8km2, a finalidade é captar o máximo de recursos como armas, munição e proteção ao mesmo tempo que 
o jogador deve se proteger e eliminar os outros 99 oponentes.
A Tecent disponibilizou um dataset de treino/teste onde o desafio de predizer quais os jogadores ficaram em primeiro lugar na partida, isso é, foi o único dos 100 players a ficar vivo no final desta sangrenta e emocionante carnificina. 

### Vence quem tiver mais sangue frio, banhada de atenção e com uma apitada de sorte.
	

Vamos aproveitar então e tentar descobrir quais skills nós precisamos adquirir para tentar vencer este jogo tão competitivo e desafiador. vem comigo.....
	
Para nos ajudar foram disponibilizado 28 features, sendo uma delas a nossa variavel **[winPlacePerc]**, que diz em qual posição o jogador teminou a partida. Lembrando que a colocação do vencerdor é 1.0, o vice é 0.99 e assim por diante, então vamos traduzir nosso Dataset:
"""

''' 
DBNOs.............Número de jogadores inimigos derrubados.
assists...........Número de jogadores inimigos que este jogador danificou que foram mortos por companheiros de equipe.
boosts............Número de itens de impulso usados.
damageDealt.......Danos totais causados. Nota: Danos auto-infligidos são subtraídos.
headshotKills.....Número de jogadores inimigos mortos com tiros na cabeça.
heals.............Número de itens de cura usados.
Id................Id do jogador
killPlace.........Ranking em jogo de número de jogadores inimigos mortos.
killPoints........Ranking externo baseado em mortes do jogador. (Pense nisso como um ranking Elo onde só mata 
                  importa.) Se houver um valor diferente de -1 em rankPoints, então qualquer 0 em killPoints deve 
                  ser tratado como um "Nenhum".
killStreaks.......Número máximo de jogadores inimigos mortos em um curto espaço de tempo.
kills.............Número de jogadores inimigos mortos.
longestKill.......Maior distância entre jogador e jogador morto no momento da morte. Isso pode ser enganoso, como 
                  derrubar um jogador e afastar pode levar a uma grande estatística longestestKill.
matchDuration.....Duração do jogo em segundos.
matchId...........ID para identificar correspondência. Não há jogos que estejam no conjunto de treinamento e testes.
matchType.........String identificando o modo de jogo de onde os dados vêm. Os modos padrão são "solo", "duo", 
                  "esquadrão", "solo-fpp", "duo-fpp" e "squad-fpp"; outros modos são de eventos ou correspondências
                  personalizadas.
rankPoints........Elo-como ranking do jogador. Este ranking é inconsistente e está sendo preterido na próxima versão
                  da API, então use com cautela. Valor de -1 ocorre de "Nenhum".
revives...........Número de vezes que este jogador reviveu companheiros de equipe.
rideDistance......Distância total percorrida em veículos medidos em metros.
roadKills.........Número de mortes enquanto em um veículo.
swimDistance......Distância total percorrida pela natação medida em metros.
TeamKills.........Número de vezes que este jogador matou um companheiro de equipe.
vehicleDestroys...Número de veículos destruídos.
walkDistance......Distância total percorrida a pé medida em metros.
weaponsAcquired...Número de armas captadas.
winPoints.........Ranking externo baseado em vitórias do jogador. (Pense nisso como um ranking Elo onde só a vitória
                  importa.) Se houver um valor diferente de -1 em rankPoints, então qualquer 0 em winPoints deve    
                  ser tratado como um "Nenhum".
groupId...........ID para identificar um grupo dentro de uma correspondência. Se o mesmo grupo de jogadores joga em
                  jogos diferentes, eles terão um groupId diferente de cada vez.
numGroups.........Número de grupos para os os que temos dados na partida.
maxPlace..........Pior colocação para a onde temos dados na partida. Isso pode não corresponder com numGroups, como
                  às vezes os dados salta sobre colocações.
winPlacePerc......O alvo da previsão. Esta é uma colocação vencedora percentile, onde 1 corresponde ao 1 º lugar,
                  e 0 corresponde ao último lugar no jogo. É calculado fora de maxPlace, não numGroups, por isso é
                  possível ter pedaços em falta em uma partida.
'''

"""# Bibliotecas importadas"""

from google.colab import drive
import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from google.colab import drive

#Montando o drive do Google Docs
drive.mount('/content/drive')

"""# Início da análise exploratoria"""

#Listando o diretorio para ver o nome dos arquivos
os.listdir('/content/drive/My Drive/Python/Arquivos/PubgDataSet/') #Verificando os arquivos do diretorio

#importando os datasets localizados dentro do google drive

#Dataset de treino / validação
df = pd.read_csv('/content/drive/My Drive/Python/Arquivos/PubgDataSet/train_V2.csv')

#Dataset final a ser previsto e imputado no Kaggle.
#df_validacao = pd.read_csv('/content/drive/My Drive/Python/Arquivos/PubgDataSet/test_V2.csv')

#Vamos passar o olho nas nossas Features
df.head(5)

#verificando se temos features com valores valores N/A
df.isnull().any()

#Temos valores N/A, vamos ver o quão grande é o problema da Feature com campos N/A.
df["winPlacePerc"].isnull().sum()

#Boas noticias, temos só um campo com valor NULL no nosso target.

#Não vou dropar esse registro, vou então Substituir o valores NA por 0, já que uma grande quantidade do nossos dados neste campo é 0.
df.update(df["winPlacePerc"].fillna(0))

# Vamos agora verificar o tipo de dados
df.info()

#Vamos aplicar a estatistica descritiva para ver mais algumas informações sobre o nosso dataset.
df.describe()

"""O jogo tambem pode ocorrer entre duplas e equipes de 4 jogadores, por isso os tipos, solo, duo e squad"""

#Tabela pivot para verificar quantidade de ocorrencias por tipo de jogo.

impute_grps = df.pivot_table(values=["winPlacePerc"], index=["matchType"], aggfunc=np.count_nonzero)
print(impute_grps)

#Filtrando jogares que ganharam e que não ganharam o jogo

valores0 = list(filter(lambda x: x <= 0.99, df["winPlacePerc"]))
valores1 = list(filter(lambda x: x > 0.99, df["winPlacePerc"]))

#printando os resultados
print ("Quantidade de players que NÃO ganharam:", len(valores0))
print ("Quantidade de players que GANHARAM:", len(valores1))
print ("-----------------------------------")
print ("quantidade total de jogadores:", len(valores0 + valores1))
print ("-----------------------------------")
print ('Percentual de jogares que venceram a partida, ', round(len(valores1) / len(valores0)*100),'%.' )

"""Podemos verificar no gráfico de disperssão que temos players que não mataram ninguém e venceram o jogo.

Isso é plausível se considerarmos que se o player estiver em duo ou em um squad, mesmo que ele não mate ninguem o restante do time dele pode fazer o trabalho sujo, e mesmo se ele for eliminado no início da partida e o time dele vencer, ele também vencerá junto.

Sei também que é possivel vencer o jogo eliminando somente um oponente e as vezes o seu único oponente restante se matar sozinho por acidente.

Está aí a importância de conhecer as regras de negócio, ou neste caso, as regras do jogo. =)
"""

#Usando um gráfico de dispersão para verificar a correlação entre as variavel kills e a variavel target winPlacePerc.

plt.figure(figsize=(18,5))
x_data, y_data = (df["kills"].values , df["winPlacePerc"].values)
plt.plot(y_data, x_data, 'ro', linewidth=8, marker=",", c='Blue' )
plt.ylabel('kills', c='white')
plt.xlabel('winPlacePerc', c='white')

sns.jointplot(x="winPlacePerc", y="walkDistance", data=df, height=10, ratio=3, color="r")
plt.show()

df["winPlacePerc"].describe()

# Verificando a distribuição do campo target
df["winPlacePerc"].value_counts()

#Fazendo um loop para alterar todos os valores de quem não ganhou o jogo para zero.
for idx, item in enumerate(df["winPlacePerc"]):
    if (df["winPlacePerc"][idx] <= 0.9999):
      df["winPlacePerc"][idx] = 0

#Sem essa padronização dos dados eu consegui acuracia de 69%

# Verificando a distribuição do campo target agora que só temos valores 0 de quem não ganho e valor 1 de quem venceu o jogo.
df["winPlacePerc"].value_counts()

#Verificando a correlação entre as variaveis do data set, focando na variavel target winPlacePerc
f,ax = plt.subplots(figsize=(14, 14))
sns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)
plt.show()

'''Verifiquei que walkdistance tem um valor agregado na pontuação do jogado, então criei uma nova variavel 
somando todos as variaveis que indicam distancia percorrida.'''

df["total_distance"] = (df["swimDistance"]+ df["rideDistance"])

#Verificando a correção com o novo campo total_distance.
f,ax = plt.subplots(figsize=(14, 14))
sns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)
plt.show()

"""Neste momento vou definir algumas features para testar um modelo.
- total_distance
- walkDistance
- weaponsAcquired
- revives
- killStreaks
- longestKill
- kills
- killPlace
- heals
- boosts
- headshotKills
- DBNOs
- damageDealt
- assists
"""

#Vamos dropar as features que não serão utilizadas

df = df.drop(['Id',	'groupId',	'matchId',	'killPoints',	'matchDuration',	'matchType',	'maxPlace',	'numGroups',	
             'rankPoints',	'rideDistance',	'roadKills',	'swimDistance',	'teamKills',	'vehicleDestroys',	
             'winPoints'], axis=1)

df.info()

#Convertendo variaveis float em variaveis inteiras
#Tive um problema pois o campo winPlacePerc possuia um valor Nulo

df['damageDealt'] = df['damageDealt'].astype('int')
df['longestKill'] = df['longestKill'].astype('int')
df['walkDistance'] = df['walkDistance'].astype('int')
df['total_distance'] = df['total_distance'].astype('int')
df['winPlacePerc'] = df['winPlacePerc'].astype('int')

df.dtypes

#Verificando a distribuição do dataframe antes do balanceamento dos dados
histogram_example = plt.hist(df['winPlacePerc'], bins=15)
plt.show()

"""# Balanceando os dados

Vamos utilizar o método Undersampling e Oversamplig para
balancear nosso número de ocorrencias daqueles players que ganharam ou não a partida.

![alt text](https://miro.medium.com/max/1275/1*-9Y4VyZm7OqBYAdKEmAb6w.png)
"""

#Este metodo de balanceamento dos dados UNDER faz com que as ocorrencias com maior proporção sejam diminuidas para que
#tenham a mesma quantidade de ocorrencias da variavel de menor quantidade

# Contando as classes
count_class_0, count_class_1 = df.winPlacePerc.value_counts()

# Divide as classes
df_class_0 = df[df['winPlacePerc'] == 0]
df_class_1 = df[df['winPlacePerc'] == 1]
'''
#aplicando o under
df_class_0_under = df_class_0.sample(count_class_1) #cria um novo dataset passando a Maior ocorrenciae usando o SAPLE para balancear com a Menor.
df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0) #criando um dataset baseado na junção dos novos valores.

#Plotando o gráfico
print('Random under-sampling:')
print(df_test_under.winPlacePerc.value_counts())
df_test_under.winPlacePerc.value_counts().plot(kind='bar', title='Count (winPlacePerc)',color = ['#1F77B4', '#FF7F0E']);'''

#EQUALIZANDO A BASE POR OVER SAMPLING

#aplicando o over
df_class_1_over = df_class_1.sample(count_class_0, replace=True)
df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)

print('Random over-sampling:')
print(df_test_over.winPlacePerc.value_counts())

df_test_over.winPlacePerc.value_counts().plot(kind='bar', title='Count (winPlacePerc)');

#Verificando a correção com o novo campo total_distance.
f,ax = plt.subplots(figsize=(14, 14))
sns.heatmap(df_test_over.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)
plt.show()

df_test_over.reset_index()

#separando variaveis independentes
x = df_test_over.drop(['winPlacePerc'], axis=1)
x

#separando variavel dependente
y = df_test_over['winPlacePerc']
y

#importando a biblioteca para fazer o split do data set em dados de treinamento e dados de teste.
from sklearn.model_selection  import train_test_split

#Fazendo a separação dos dados de treinamento e teste
x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.995, random_state=4)
print ('Train set:', x_train.shape,  y_train.shape)
print ('Test set:', x_test.shape,  y_test.shape)

print (' X - Quantidade de campo 1 e 0 do treinamento : ', len(list(filter(lambda x_train: 1 == 1, y))),"|" ,len(list(filter(lambda x_train: 0 == 0, y))))

print (' Y - Quantidade de campo 1 e 0 do treinamento : ', len(list(filter(lambda y_train: 1 == 1, y))),"|" ,len(list(filter(lambda y_train: 0 == 0, y))))

#Gerando o modelo usando o Kernel rbf entre as opçoes Linear,Polynomial, Radial basis function (RBF) e 4.Sigmoid
from sklearn import svm
clf = svm.SVC(kernel='rbf', gamma='auto')
clf.fit(x_train, y_train)

from datetime import datetime

datetime = datetime.now()
datetime = datetime.strftime('%d/%m/%Y  %H:%M')

print(datetime)

#importando a biblioteca para persistir o modelo
import pickle
#Salvando o modelo em um arquivo .SAV
pickle.dump(clf, open('/content/drive/My Drive/Python/Arquivos/PubgDataSet/modelo_SVM_PUBG.sav', 'wb'))

#Chamando o modelo persistido através do método LOAD
#clf = pickle.load(open('/content/drive/My Drive/Python/Arquivos/PubgDataSet/modelo_SVM_PUBG.sav', 'rb'))
#predicted = clf.predict(x_test)

clf.score(x_train, y_train)

#Predict Output
predicted = clf.predict(x_test)
predicted [0:20]

#F1 SCORE - Avaliação do modelo.

from sklearn.metrics import f1_score
f1_score(y_test, predicted, average='weighted', labels=np.unique(predicted))

#Avaliação jaccard - Avaliação do modelo
from sklearn.metrics import jaccard_score
jaccard = jaccard_score(y_test, predicted, labels=np.unique(predicted))
#print('Avaliação do modelo usando jaccard retornou um valor de acuracia de', (jaccard*100),'%')
jaccard

# Compute confusion matrix
from sklearn.metrics import classification_report, confusion_matrix
import itertools

cnf_matrix = confusion_matrix(y_test, predicted,  labels=np.unique(predicted))
np.set_printoptions(precision=2)

print (classification_report(y_test, predicted, labels=np.unique(predicted)))

#MATRIZ DE CONFUSAO
conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)
print('Confusion matrix:\n', conf_mat)

labels = ['Class 0', 'Class 1']
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)
fig.colorbar(cax)
ax.set_xticklabels([''] + labels)
ax.set_yticklabels([''] + labels)
plt.xlabel('Predicted')
plt.ylabel('Expected')
plt.show()